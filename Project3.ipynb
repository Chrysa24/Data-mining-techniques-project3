{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #                                    ΑΠΑΛΛΑΚΤΙΚΗ ΕΡΓΑΣΙΑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βιρβιδάκη Χρυσούλα 1115201600021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import defaultdict\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Διάβασμα από αρχεία δεδομένων και αποθήκευση της πληροφορίας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Στο X_train αποθηκεύω την πληροφορία του κάθε σχολίου που ανήκει στο αρχείο εκπαίδευσης. (Μέγεθος (3947, 2))\n",
    "# Στο y_train αποθηκεύω την κατηγορία στην οποία ανήκει το κάθε ένα σχόλιο από το αρχείο εκπαίδευσης. (Μέγεθος (3947, 1))\n",
    "# Στο X_test αποθηκεύω την πληροφορία του κάθε σχολίου που ανήκει στο αρχείο δοκιμής. (Μέγεθος (2235, 2))\n",
    "# Στο y_test αποθηκεύω την κατηγορία στην οποία ανήκει το κάθε ένα σχόλιο από το αρχείο δοκιμής. (Μέγεθος (2235, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train.csv\",usecols=['Date', 'Comment']) \n",
    "y_train = pd.read_csv(\"data/train.csv\",usecols=['Insult'])\n",
    "\n",
    "\n",
    "X_test = pd.read_csv(\"data/impermium_verification_set.csv\",usecols=['Date', 'Comment']) \n",
    "y_test = pd.read_csv(\"data/impermium_verification_labels.csv\",usecols=['Insult'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Προεπεξεργασία και καθάρισμα των δεδομένων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αρχικά φροντίζω να καθαρίσω το αρχείο από τους χαρακτήρες  “\\n”, \"\\xa0\", \"\\xc2\", \"\\u\", \"\\x\".\n",
    "# Στη συνέχεια καθαρίζω από τα urls.\n",
    "# Έπειτα καθαρίζω από συμβολοσειρές που περιέχουν το σύμβολο '@', καθώς και από συμβολοσειρές που περιέχουν αριθμούς,\n",
    "# αλλά και τις ημερομηνίες,καθώς δεν δίνουν κάποια χρήσιμη πληροφορία, αλλά το αντίθετο.\n",
    "# Τέλος, αφαιρώ τα σημεία στίξης και μετατρέπω όλους τους χαρακτήρες σε μικρούς."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Καθαρισμός των test δεδομένων\n",
    "    \n",
    "X_test['Comment'] = X_test['Comment'].astype(str)\n",
    "X_test['Comment'] = X_test['Comment'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "X_test['Comment'] = X_test['Comment'].apply(lambda x: x.replace('\\\\xa0', ' '))\n",
    "X_test['Comment']=X_test['Comment'].replace(r'\\\\xc2', u' ',regex=True)\n",
    "X_test['Comment']=X_test['Comment'].replace(r'\\\\u', u' ',regex=True)\n",
    "X_test['Comment']=X_test['Comment'].replace(r'\\\\x', u' ',regex=True)\n",
    "\n",
    "X_test['Comment'] = X_test['Comment'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "\n",
    "X_test['Comment'].replace(r\"\\S+\\@\\S+\", \" \", regex=True ,inplace=True)\n",
    "X_test['Comment'].replace(r\"\\S+\\d+\\S+\", \" \", regex=True,inplace=True)\n",
    "X_test['Comment'].replace(r\"(\\d{1,2})[/.-](\\d{1,2})[/.-](\\d{2,4})+\", \" DATE \", regex=True,inplace=True)\n",
    "\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "X_test['Comment'] = X_test['Comment'].apply(lambda x: x.translate(table))\n",
    "X_test['Comment'] = X_test['Comment'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Καθαρισμός των train δεδομένων\n",
    "\n",
    "X_train['Comment'] = X_train['Comment'].astype(str)\n",
    "X_train['Comment'] = X_train['Comment'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "X_train['Comment'] = X_train['Comment'].apply(lambda x: x.replace('\\\\xa0', ' '))\n",
    "X_train['Comment']=X_train['Comment'].replace(r'\\\\xc2', u' ',regex=True)\n",
    "X_train['Comment']=X_train['Comment'].replace(r'\\\\u', u' ',regex=True)\n",
    "X_train['Comment']=X_train['Comment'].replace(r'\\\\x', u' ',regex=True)\n",
    "\n",
    "X_train['Comment'] = X_train['Comment'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "\n",
    "X_train['Comment'].replace(r\"\\S+\\@\\S+\", \" \", regex=True ,inplace=True)\n",
    "X_train['Comment'].replace(r\"\\S+\\d+\\S+\", \" \", regex=True,inplace=True)\n",
    "X_train['Comment'].replace(r\"(\\d{1,2})[/.-](\\d{1,2})[/.-](\\d{2,4})+\", \" DATE \", regex=True,inplace=True)\n",
    "\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "X_train['Comment'] = X_train['Comment'].apply(lambda x: x.translate(table))\n",
    "X_train['Comment'] = X_train['Comment'].apply(lambda x: x.lower()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Μετατροπή των σχολίων σε word vectors χρησιμοποιώντας τον CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "X_test_counts = count_vect.transform(X_test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Δημιουργώ αντίγραφα των πινάκων γιατί στην συνέχεια θα τα χρειαστώ\n",
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification  NaiveBayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μετρικές απόδοσης: classification accuracy, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αρχικά υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.6693385645211432\n",
      "Train accuracy 0.6572065264475141\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(),  scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.575294441389866\n",
      "Test Accuracy:  0.5901565995525727\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel())\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βελτιστοποίηση του Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1)  lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "new_X_train['Comment'] = X_train['Comment'].apply(lambda x: [ lemmatizer.lemmatize(w,\"n\") for w in nltk.word_tokenize(x)])\n",
    "new_X_test['Comment'] = X_test['Comment'].apply(lambda x: [ lemmatizer.lemmatize(w,\"n\") for w in nltk.word_tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Έπειτα από το lemmatization μετατρέπω τις λίστες των λέξεων που αποτελούν ένα σχόλιο σε συμβολοσειρά, και ακολουθώ\n",
    "# την ίδια διαδικασία με πριν, μετατρέποντας τα σχόλια σε word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in new_X_train.iterrows(): \n",
    "    j[\"Comment\"] = ' '.join(map(str, j[\"Comment\"]))\n",
    "for i,j in new_X_test.iterrows(): \n",
    "    j[\"Comment\"] = ' '.join(map(str, j[\"Comment\"]))\n",
    "    \n",
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "X_test_counts = count_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εφαρμόζω και πάλι το Classification NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.6648367875719192\n",
      "Train accuracy 0.6506194349521104\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.5664088461738794\n",
      "Test Accuracy:  0.5816554809843401\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel())\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Χρησιμοποιώ τα δεδομένα τα αρχικά και όχι αυτά που προέκυψαν από τις προηγούμενες βελτιστοποιήσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "new_X_train['Comment'] = [w for w in X_train['Comment'] if not w in stop_words]\n",
    "new_X_test['Comment'] = [w for w in X_test['Comment'] if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Έπειτα από την αφαίρεση των stop words ακολουθώ την ίδια διαδικασία με πριν, μετατρέποντας τα σχόλια σε word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "X_test_counts = count_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εφαρμόζω και πάλι το Classification NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.668140903228535\n",
      "Train accuracy 0.6554337328135278\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(),scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.5723712016794856\n",
      "Test Accuracy:  0.5883668903803132\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel())\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Χρησιμοποιώ τα δεδομένα τα αρχικά και όχι αυτά που προέκυψαν από τις προηγούμενες βελτιστοποιήσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ακολουθώ την ίδια διαδικασία με πριν, μετατρέποντας τα σχόλια σε word vectors προσθέτωντας αυτή τη φορά την παράμετρο\n",
    "# ngram_range = (2,2) με την οποία χρησιμοποιώ φράσεις 2 λέξεων, αντί για μοναδικές λέξεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range = (2,2))\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εφαρμόζω και πάλι το Classification NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.6889410450222749\n",
      "Train accuracy 0.683310415729615\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), cv=10, scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), cv=10,scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.613814555920073\n",
      "Test Accuracy:  0.6214765100671141\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel(), cv=9)\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Laplace Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Χρησιμοποιώ τα δεδομένα τα αρχικά και όχι αυτά που προέκυψαν από τις προηγούμενες βελτιστοποιήσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ακολουθώ την ίδια διαδικασία με πριν, μετατρέποντας τα σχόλια σε word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range = (1,2))\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εφαρμόζω και πάλι το Classification NaiveBayes. Αυτή τη φορά χρησιμοποιώ τον MultinomialNB ο οποίος μου δίνει την δυνατότητα\n",
    "# να προσθέσω την παράμετρο alpha δίνοντας της τιμή 1.0, ώστε να κάνω την βελτιστοποίηση με Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = MultinomialNB(alpha=1.0)\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.7646584138944055\n",
      "Train accuracy 0.7565205937158646\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), cv=10,scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(simple_gnb, X_train_counts.toarray(), y_train_text.ravel(), cv=10,scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.6400059706986009\n",
      "Test Accuracy:  0.6568232662192394\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel(), cv=10)\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Συμπεράσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Τα scores για τα test αρχεία πριν κάνω οποιαδήποτε βελτιστοποίηση κυμαίνονταν το f1 score στο 0.57 ενώ το Accuracy στο 0.59\n",
    "# Παρατήρησα ότι με τους δύο πρώτους τρόπους βελτιστοποίησης δεν υπήρξε κάποια αλλαγή στα σκορ, παρέμειναν στις ίδιες περίπου τιμές\n",
    "# Αντίθετα με την χρήση των bigrams παρατήρησα μία αύξηση στα scores καθώς οι τιμές τους ανέβηκαν στο 0.61 και 0.62 αντίστοιχα.\n",
    "# Ακόμα μεγαλύτερη αύξηση υπήρξε με τη χρήση του Laplace Smoothing, όπου τα scores ανέβηκαν στις τιμές 0.64 και 0.65 αντίστοιχα.\n",
    "# Καταλήγουμε λοιπόν στο ότι για τα συγκεκριμένα δεδομένα μας πιο αποδοτικές μέθοδοι βελτιστοποίησης ήταν η χρήση των bigrams\n",
    "# και του Laplace Smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Δημιουργία πιο σύνθετου πίνακα χαρακτηριστικών με part-of-speech χαρακτηριστικά και TF-IDF-based χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ακολουθώ την ίδια διαδικασία με πριν, μετατρέποντας τα σχόλια σε word vectors, με τη διαφορά ότι τώρα χρησιμοποιώ τον\n",
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_features=200,min_df=1)  #len=200\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)     # shape (3947,200)\n",
    "X_test_counts = count_vect.transform(X_test_text)           # shape (2235,200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Παρακάτω για κάθε ένα σχόλιο βρίσκω τα part-of-speech χαρακτηριστικά των λέξεων του. Μετράω το σύνολο των λέξεων του σχολίου\n",
    "# που είναι noun, verb, adverb και adjective και στη συνέχεια υπολογίζω τα ποσοστά αυτών με βάση τον συνολικό αριθμό των λέξεων\n",
    "# του σχολίου. Αυτά τα ποσοστά τα αποθηκεύω σε ένα Dataframe με 4 στήλες (1 για το κάθε ποσοστό). Αυτό το Dataframe στο τέλος\n",
    "# της επανάληψης θα έχει τόσες γραμμές όσα και τα σχόλια του κάθε αρχείου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αρχικά δουλεύω πάνω στα train δεδομένα\n",
    "\n",
    "POS_train = pd.DataFrame(columns = ['fractionAdverbs', 'fractionVerbs', 'fractionAdjectives', 'fractionNouns']) \n",
    "\n",
    "for i,j in X_train.iterrows(): \n",
    "    \n",
    "    tokens = nltk.word_tokenize(j[\"Comment\"])\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    counts = Counter( tag for word,  tag in tags)\n",
    "    if len(tags)!=0:\n",
    "        nouns = (counts['NN']+counts['NNS']+counts['NNP']+counts['NNPS'])/len(tags)\n",
    "        verbs = (counts['VB']+counts['VBG']+counts['VBD']+counts['VBN']+counts['VBP']+counts['VBZ'])/len(tags)\n",
    "        adverbs = (counts['RB']+counts['RBR']+counts['RBS'])/len(tags)\n",
    "        adjectives = (counts['JJ']+counts['JJR']+counts['JJS'])/len(tags)\n",
    "        \n",
    "        POS_train = POS_train.append({'fractionAdverbs' : adverbs , 'fractionVerbs' : verbs,'fractionAdjectives' : adjectives,'fractionNouns' : nouns} , ignore_index=True)\n",
    "    else:\n",
    "        POS_train = POS_train.append({'fractionAdverbs' : 0 , 'fractionVerbs' : 0,'fractionAdjectives' : 0,'fractionNouns' : 0} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφού έχω υπολογίσει τόσο τα TF-IDF-based χαρακτηριστικά όσο και τα  part-of-speech χαρακτηριστικά του κάθε σχολίου,\n",
    "# τα ενώνω σε έναν ενιαίο πίνακα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pos_X_train = np.hstack((X_train_counts.toarray(),POS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ακολουθώ την ίδια διαδικασία και για τα test δεδομένα\n",
    "\n",
    "POS_test = pd.DataFrame(columns = ['fractionAdverbs', 'fractionVerbs', 'fractionAdjectives', 'fractionNouns']) \n",
    "\n",
    "for i,j in X_test.iterrows(): \n",
    "    \n",
    "    tokens = nltk.word_tokenize(j[\"Comment\"])\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    counts = Counter( tag for word,  tag in tags)\n",
    "    if len(tags)!=0:\n",
    "        nouns = (counts['NN']+counts['NNS']+counts['NNP']+counts['NNPS'])/len(tags)\n",
    "        verbs = (counts['VB']+counts['VBG']+counts['VBD']+counts['VBN']+counts['VBP']+counts['VBZ'])/len(tags)\n",
    "        adverbs = (counts['RB']+counts['RBR']+counts['RBS'])/len(tags)\n",
    "        adjectives = (counts['JJ']+counts['JJR']+counts['JJS'])/len(tags)\n",
    "        \n",
    "        POS_test = POS_test.append({'fractionAdverbs' : adverbs , 'fractionVerbs' : verbs,'fractionAdjectives' : adjectives,'fractionNouns' : nouns} , ignore_index=True)\n",
    "    else:\n",
    "        POS_test = POS_test.append({'fractionAdverbs' : 0 , 'fractionVerbs' : 0,'fractionAdjectives' : 0,'fractionNouns' : 0} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pos_X_test = np.hstack((X_test_counts.toarray(),POS_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "tfidf_clf = clf.fit(tfidf_pos_X_train, y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.7843145830812822\n",
      "Train accuracy 0.8084622419021033\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(tfidf_clf, tfidf_pos_X_train, y_train_text.ravel(), scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(tfidf_clf, tfidf_pos_X_train, y_train_text.ravel(), scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.6661764706585737\n",
      "Test Accuracy:  0.6702460850111857\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(tfidf_clf, tfidf_pos_X_test, y_test_text.ravel())\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "tfidf_clf = clf.fit(tfidf_pos_X_train, y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Υπολογίζω τα scores με τις μετρικές αυτές για τα train δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1s 0.6217078924673287\n",
      "Train accuracy 0.7342286191608302\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(tfidf_clf, tfidf_pos_X_train, y_train_text.ravel(), cv=10, scoring='f1_weighted')\n",
    "print ('Train f1s', np.mean(f1s))\n",
    "\n",
    "accuracy = cross_val_score(tfidf_clf, tfidf_pos_X_train, y_train_text.ravel(), cv=10,scoring='accuracy')\n",
    "print(\"Train accuracy\", np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Και έπειτα υπολογίζω τα αντίστοιχα scores με τις ίδες μετρικές για τα test δεδομένα\n",
    "# και αξιολογώ την απόδοση της μεθόδου κατηγοριοποίησης έπειτα από την βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.5800385986640617\n",
      "Test Accuracy:  0.6308724832214765\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(tfidf_clf, tfidf_pos_X_test, y_test_text.ravel(), cv=10)\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Συμπεράσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Έπειτα από τα παραπάνω καταλήγω ότι ο συνδυασμός των part-of-speech χαρακτηριστικών και TF-IDF-based χαρακτηριστικών\n",
    "# λειτούργησε πιο αποδιτκά με τον SVM Classifier. \n",
    "# Έπειτα από πειραματισμούς για την τιμή του ορίσματος ngram_range στον TfidfVectorizer κατέληξα ότι μεγαλύτερα σκορ\n",
    "# έπαιρνα για ngram_range=(1,2).\n",
    "# Ακόμα επειδή τα part-of-speech χαρακτηριστικά είναι μόνο 4 ανά σχόλιο, έπρεπε να ρυθμίσω τον αριθμό των features\n",
    "# που δημιουργούνταν από τον TfidfVectorizer. Με πολλά πειράματα είδα ότι για max_features=200 παίρνω τα υψηλότερα σκορ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Πειραματισμοί για περαιτέρω βελτιστοποιήσεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train.copy()\n",
    "new_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = new_X_train[\"Comment\"].values\n",
    "y_train_text = y_train.values\n",
    "\n",
    "X_test_text = new_X_test[\"Comment\"].values\n",
    "y_test_text = y_test.values\n",
    "\n",
    "count_vect = TfidfVectorizer(stop_words='english',ngram_range=(1,2),max_features=2000)\n",
    "X_train_counts = count_vect.fit_transform(X_train_text)\n",
    "X_test_counts = count_vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnb = RandomForestClassifier(max_depth=15, random_state=0,n_estimators=50, max_features=1000) #0.65\n",
    "#gnb = MultinomialNB(alpha=1.0) #0.70\n",
    "\n",
    "gnb = svm.SVC(kernel='linear', C=1.0,gamma='scale') #0.71\n",
    "simple_gnb = gnb.fit(X_train_counts.toarray(), y_train_text.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score:  0.7111200599173014\n",
      "Test Accuracy:  0.7127516778523489\n"
     ]
    }
   ],
   "source": [
    "y_pred = cross_val_predict(simple_gnb, X_test_counts.toarray(), y_test_text.ravel())\n",
    "F1_score = f1_score(y_test_text.ravel(), y_pred, average='weighted')\n",
    "print('Test f1 score: ' , F1_score)\n",
    "\n",
    "Accuracy = accuracy_score(y_test_text.ravel(), y_pred)\n",
    "print(\"Test Accuracy: \", Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Συμπεράσματα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αρχικά πειραματίστηκα με την χρήση το απλού CountVectorizer και με τις παραμέτρους του, όμως στο τέλος κατέληξα ότι υψηλότερα\n",
    "# σκορ έπαιρνα με τον TfidfVectorizer. Ακόμα μεγάλες διαφορές είχε ο TfidfVectorizer ανάλογα με την τιμή που έδινα στο όρισμα:\n",
    "# ngram_range με υψηλότερο τελικά σκορ να δίνει όταν χρησιμοποιώ τιμ΄΄΄η: (1,1).\n",
    "\n",
    "# Ακόμα δοκίμασα διάφορους classifiers. Ανάμεσα σε αυτούς της οικογένειας Naive Bayes, καταλληλότερος ήταν με διαφορά ο \n",
    "# MultinomialNB(70%). Ωστόσο παρόμοια σκορ δίνει και ο SVM (πάνω από 70%). Αντίθετα ο KNeighborsClassifier στην περίπτωση μου\n",
    "# δεν έδειξε να είναι πολύ αποδοτικός αφού τα σκορ που πήρα ήταν κάτω από 60%.\n",
    "# Αρκετά αποδοτικός ήταν και ο RandomForestClassifier που έδωσε σκορ γύρω στο 65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
